# Gemini API Setup Guide - Complete Configuration

## ğŸš€ Why Gemini Instead of Azure?

âœ… **No approval needed** - Get API key instantly  
âœ… **Generous free tier** - 1500 requests/day  
âœ… **Multimodal** - Text + Vision in one model  
âœ… **Cheaper** - $0.075/1M tokens (vs Azure $30/1M)  
âœ… **Better for students** - No credit card required  

---

## ğŸ“‹ Quick Setup (5 Minutes)

### Step 1: Get Gemini API Key

```bash
1. Go to: https://makersuite.google.com/app/apikey
2. Click "Create API Key"
3. Copy your key (starts with "AIza...")
```

**That's it!** No resource groups, no regions, no approvals needed.

---

### Step 2: Install Local CLIP (Mac)

```bash
# Create Python environment
cd /Users/kartiksharma/Desktop/Projects/pcod_app/backend
python3 -m venv venv
source venv/bin/activate

# Install CLIP and dependencies
pip install torch torchvision
pip install git+https://github.com/openai/CLIP.git
pip install pillow numpy flask

# Test CLIP
python3 -c "import clip; print(clip.available_models())"
# Should show: ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']
```

**Recommended model**: `ViT-B/32` (fast, good accuracy)

---

### Step 3: Setup Deepgram (Voice)

```bash
1. Sign up: https://deepgram.com/
2. Get $200 free credits
3. Copy API key from dashboard
```

---

### Step 4: Configure Environment Variables

Update `.env`:

```bash
# Gemini API
GEMINI_API_KEY=AIza...your_key_here

# Deepgram (Voice)
DEEPGRAM_API_KEY=your_deepgram_key

# Supabase (already configured)
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_key

# Local CLIP settings
CLIP_MODEL=ViT-B/32
CLIP_DEVICE=mps  # Use Apple Silicon GPU

# API Settings
API_BASE_URL=http://localhost:3000
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              React Native App                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           NestJS/Express Backend                     â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Gemini  â”‚  â”‚   CLIP   â”‚  â”‚ Deepgram â”‚         â”‚
â”‚  â”‚ (Cloud)  â”‚  â”‚ (Local)  â”‚  â”‚ (Cloud)  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Supabase (Database)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Service Breakdown

### 1. **Gemini 2.0 Flash** (Text + Vision)
- Facial analysis (hirsutism, acne)
- Food detection & nutrition
- Medical OCR
- Risk assessment
- Chatbot conversations

### 2. **Local CLIP** (Image Embeddings)
- Fast image classification
- Similarity search
- Embedding generation
- Runs on your Mac's GPU (MPS)

### 3. **Deepgram** (Voice)
- Speech-to-Text (Nova-2)
- Text-to-Speech (Aura)

---

## ğŸ’° Cost Comparison

| Service | Free Tier | Paid Cost |
|---------|-----------|-----------|
| **Gemini API** | 1500 req/day | $0.075/1M tokens |
| **Azure OpenAI** | âŒ None | $30/1M tokens |
| **Local CLIP** | âœ… Free (runs locally) | $0 |
| **Deepgram** | $200 credits | $0.0043/min |

**Monthly cost for 1000 users**: ~$15-20 (vs $96 with Azure!)

---

## ğŸš€ Backend Setup

### Install Dependencies

```bash
cd backend

# Node.js dependencies
npm install @google/generative-ai express cors dotenv multer winston

# Python dependencies (for CLIP)
source venv/bin/activate
pip install torch torchvision clip pillow flask numpy
```

### Start Services

```bash
# Terminal 1: Node.js backend
npm run dev

# Terminal 2: Python CLIP server
source venv/bin/activate
python clip_server.py
```

---

## ğŸ§ª Test Setup

### Test Gemini API

```bash
curl -X POST http://localhost:3000/api/test/gemini \
  -H "Content-Type: application/json" \
  -d '{"message": "What is PCOS?"}'
```

### Test Local CLIP

```bash
curl -X POST http://localhost:5001/classify \
  -F "image=@test_image.jpg" \
  -F "labels=hirsutism,acne,normal"
```

### Test Deepgram

```bash
curl -X POST http://localhost:3000/api/voice/transcribe \
  -F "audio=@test_audio.wav"
```

---

## ğŸ“Š Gemini API Limits

### Free Tier:
- **1500 requests per day**
- **32K tokens per request**
- **Rate limit**: 60 RPM

### Paid Tier ($0.075/1M tokens):
- **Unlimited requests**
- **Rate limit**: 1000 RPM

**For your app**: Free tier = ~50 users/day

---

## ğŸ”§ Running CLIP on Mac

### Why CLIP Locally?

âœ… **Zero cost** - No API fees  
âœ… **Fast** - <100ms inference on M-series  
âœ… **Privacy** - Data stays local  
âœ… **Reliable** - No internet needed  

### Performance on Apple Silicon:

| Model | Speed (M1/M2) | Accuracy |
|-------|---------------|----------|
| ViT-B/32 | ~50ms | Good |
| ViT-B/16 | ~100ms | Better |
| ViT-L/14 | ~200ms | Best |

**Recommendation**: Use ViT-B/32 for real-time, ViT-L/14 for batch processing

---

## ğŸ¯ Use Cases

### Gemini Vision (Cloud):
- Facial analysis (detailed descriptions)
- Food detection (complex reasoning)
- Medical OCR (text extraction)
- HRV interpretation (contextual analysis)

### CLIP (Local):
- Quick image classification
- Facial feature detection
- Food categorization
- Image embeddings for search

**Strategy**: Use CLIP for fast classification, Gemini for detailed analysis

---

## ğŸ” Security

### API Keys:
```bash
# Never commit these!
.env
backend/.env
```

### CORS:
```typescript
app.use(cors({
  origin: 'http://localhost:8081'  // Expo dev server only
}));
```

---

## ğŸ“š API Documentation

### Gemini API:
- Docs: https://ai.google.dev/docs
- Models: https://ai.google.dev/models/gemini
- Pricing: https://ai.google.dev/pricing

### CLIP:
- GitHub: https://github.com/openai/CLIP
- Paper: https://arxiv.org/abs/2103.00020
- Examples: https://github.com/openai/CLIP#usage

### Deepgram:
- Docs: https://developers.deepgram.com/
- Models: Nova-2 (STT), Aura (TTS)

---

## âœ… Setup Checklist

- [ ] Got Gemini API key (5 mins)
- [ ] Installed Python 3.10+ (if needed)
- [ ] Installed CLIP locally
- [ ] Created Deepgram account
- [ ] Updated all keys in `.env`
- [ ] Installed Node dependencies
- [ ] Installed Python dependencies
- [ ] Tested Gemini API
- [ ] Tested local CLIP
- [ ] Started backend servers

**Total setup time**: ~20 minutes

---

## ğŸš¨ Troubleshooting

### "torch not found"
```bash
# Install PyTorch with MPS support (Apple Silicon)
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### "CLIP model download slow"
```bash
# Models download on first use (~350MB for ViT-B/32)
# Be patient, it's one-time
```

### "Gemini API quota exceeded"
```bash
# Free tier: 1500 requests/day
# Solution: Wait 24 hours or upgrade to paid tier
```

---

**You're ready to build! Much simpler than Azure! ğŸš€**
